#!/usr/bin/env python3
"""BM25 Retriever - LangChain ê¸°ë°˜ í‚¤ì›Œë“œ ê²€ìƒ‰"""

import sys
from pathlib import Path
from typing import List

sys.path.insert(0, str(Path(__file__).parent.parent))

from langchain_community.retrievers import BM25Retriever
from langchain_core.documents import Document
from qdrant_client import QdrantClient
from config.settings import (
    QDRANT_COLLECTION,
    QDRANT_URL,
    QDRANT_USE_SERVER,
    get_qdrant_path,
    get_collection_name
)

# ì‹±ê¸€í†¤ íŒ¨í„´: ë¬¸ì„œ ìºì‹± (Qdrant lock ë°©ì§€)
_documents_cache = {}


def load_documents_from_qdrant(date_filter: tuple = None, preset: str = None) -> List[Document]:
    """
    Qdrantì—ì„œ ëª¨ë“  ë¬¸ì„œë¥¼ ë¡œë“œí•˜ì—¬ LangChain Documentë¡œ ë³€í™˜

    Args:
        date_filter: (start_date, end_date) íŠœí”Œ (ISO í˜•ì‹)
        preset: ì„ë² ë”© í”„ë¦¬ì…‹ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
    """
    import os

    # ì»¬ë ‰ì…˜ ì´ë¦„ ê²°ì •
    collection_name = get_collection_name(preset)

    # Qdrant í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ì„œë²„ ëª¨ë“œ ìš°ì„ )
    if QDRANT_USE_SERVER:
        # ìºì‹œ í‚¤ì— ì»¬ë ‰ì…˜ ì´ë¦„ í¬í•¨
        cache_key = (QDRANT_URL, collection_name, date_filter)
        client = QdrantClient(url=QDRANT_URL, check_compatibility=False)
    else:
        # ë ˆê±°ì‹œ: ë¡œì»¬ íŒŒì¼ ëª¨ë“œ
        qdrant_path = get_qdrant_path()
        cache_key = (qdrant_path, QDRANT_COLLECTION, date_filter)
        client = QdrantClient(path=qdrant_path)
        collection_name = QDRANT_COLLECTION

    # ìºì‹œ í™•ì¸
    if cache_key in _documents_cache:
        return _documents_cache[cache_key]

    try:
        # scroll íŒŒë¼ë¯¸í„° ì„¤ì •
        scroll_params = {
            "collection_name": collection_name,
            "limit": 10000,
            "with_payload": True,
            "with_vectors": False  # ë²¡í„°ëŠ” í•„ìš” ì—†ìŒ
        }

        # ëª¨ë“  í¬ì¸íŠ¸ ê°€ì ¸ì˜¤ê¸° (ë‚ ì§œ í•„í„°ë§ì€ Pythonì—ì„œ ì²˜ë¦¬)
        scroll_result = client.scroll(**scroll_params)

        documents = []
        for point in scroll_result[0]:
            # payload êµ¬ì¡° ê°ì§€ (ë‘ ê°€ì§€ í˜•ì‹ ì§€ì›)
            # í˜•ì‹ 1: metadata í•„ë“œì— ì¤‘ì²© (upstage ë“±)
            # í˜•ì‹ 2: payload ìµœìƒìœ„ì— ì§ì ‘ ì €ì¥ (openai-large ë“±)

            # page_content ì¶”ì¶œ (ì—¬ëŸ¬ í•„ë“œëª… ì‹œë„)
            page_content = (
                point.payload.get("page_content") or
                point.payload.get("combined_text") or
                point.payload.get("text") or
                ""
            )

            # ë¹ˆ ë¬¸ì„œëŠ” ê±´ë„ˆë›°ê¸°
            if not page_content or not page_content.strip():
                continue

            # metadata ì¶”ì¶œ (ë‘ ê°€ì§€ êµ¬ì¡° ì§€ì›)
            if "metadata" in point.payload:
                # í˜•ì‹ 1: metadata í•„ë“œì— ì¤‘ì²©
                metadata_dict = point.payload["metadata"]
            else:
                # í˜•ì‹ 2: payload ìµœìƒìœ„ì— ì§ì ‘ ì €ì¥
                metadata_dict = point.payload

            # ë‚ ì§œ í•„í„°ë§ (Python ë ˆë²¨ì—ì„œ ì²˜ë¦¬)
            if date_filter:
                start_date, end_date = date_filter

                # propertiesì—ì„œ ë‚ ì§œ ì¶”ì¶œ
                properties = metadata_dict.get("properties", {})

                # ìƒˆë¡œìš´ ë‚ ì§œ_start í•„ë“œ ìš°ì„  ì‚¬ìš© (vectordb ì¬êµ¬ì¶• í›„)
                date_start = properties.get("ë‚ ì§œ_start", "")

                # ë‚ ì§œ_start í•„ë“œê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš© (í•˜ìœ„ í˜¸í™˜ì„±)
                if not date_start:
                    last_edited = properties.get("ìµœì¢… í¸ì§‘ ì¼ì‹œ", "")
                    created = properties.get("ìƒì„± ì¼ì‹œ", "")

                    # ë‚ ì§œ ë²”ìœ„ ì²´í¬
                    in_range = False
                    for date_str in [last_edited, created]:
                        if date_str and start_date <= date_str <= end_date:
                            in_range = True
                            break
                else:
                    # ë‚ ì§œ_start í•„ë“œë¡œ í•„í„°ë§ (ê¶Œì¥)
                    in_range = date_start and start_date <= date_start <= end_date

                # ë²”ìœ„ ë°–ì´ë©´ ê±´ë„ˆë›°ê¸°
                if not in_range:
                    continue

            # metadata ì¶”ì¶œ
            metadata = {
                "page_id": metadata_dict.get("page_id", ""),
                "page_title": metadata_dict.get("page_title", ""),
                "section_title": metadata_dict.get("section_title", ""),
                "section_path": metadata_dict.get("section_path", ""),
                "chunk_id": metadata_dict.get("chunk_id", ""),
                "has_image": metadata_dict.get("has_image", False),
                "image_paths": metadata_dict.get("image_paths", []),
                "image_descriptions": metadata_dict.get("image_descriptions", []),
            }

            doc = Document(
                page_content=page_content,
                metadata=metadata
            )
            documents.append(doc)

        # ìºì‹œì— ì €ì¥
        _documents_cache[cache_key] = documents

        return documents
    finally:
        # client ëª…ì‹œì ìœ¼ë¡œ ë‹«ê¸°
        client.close()


def get_bm25_retriever(k: int = 5, date_filter: tuple = None, preset: str = None) -> BM25Retriever:
    """
    BM25 Retriever ìƒì„±

    Args:
        k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
        date_filter: (start_date, end_date) íŠœí”Œ (ISO í˜•ì‹)
        preset: ì„ë² ë”© í”„ë¦¬ì…‹ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)

    Returns:
        BM25Retriever ì¸ìŠ¤í„´ìŠ¤
    """
    # Qdrantì—ì„œ ë¬¸ì„œ ë¡œë“œ
    documents = load_documents_from_qdrant(date_filter=date_filter, preset=preset)

    # ë¬¸ì„œê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
    if not documents:
        print(f"âš ï¸ ë‚ ì§œ í•„í„°({date_filter})ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        # ë¹ˆ retriever ë°˜í™˜ (ìµœì†Œ 1ê°œì˜ ë”ë¯¸ ë¬¸ì„œ í•„ìš”)
        from langchain_core.documents import Document
        documents = [Document(page_content="", metadata={})]

    # BM25 Retriever ìƒì„±
    retriever = BM25Retriever.from_documents(documents)
    retriever.k = k

    return retriever


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    print("ğŸ” BM25 Retriever í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # Retriever ìƒì„±
    retriever = get_bm25_retriever(k=3)

    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "RAG ì‹œìŠ¤í…œì€ ì–´ë–»ê²Œ ë™ì‘í•˜ë‚˜ìš”?",
        "ì„ë² ë”© ëª¨ë¸ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
        "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë€ ë¬´ì—‡ì¸ê°€ìš”?"
    ]

    for query in test_queries:
        print(f"\nğŸ“ Query: {query}")
        print("-" * 60)

        results = retriever.invoke(query)

        for i, doc in enumerate(results, 1):
            print(f"\n[{i}] {doc.metadata.get('page_title', 'Unknown')}")
            print(f"    Section: {doc.metadata.get('section_title', 'N/A')}")
            print(f"    Content: {doc.page_content[:200]}...")

    print("\n" + "=" * 60)
    print("âœ… BM25 Retriever í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
