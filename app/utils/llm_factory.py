#!/usr/bin/env python3
"""LLM Factory - Azure AIì™€ OpenRouter LLM ìƒì„±ì„ ìœ„í•œ íŒ©í† ë¦¬ í•¨ìˆ˜"""

import os
from typing import Optional
from langchain.chat_models import init_chat_model
from langchain_openai import ChatOpenAI


# Azure AI ëª¨ë¸ ID/ì´ë¦„ì„ OpenRouter ëª¨ë¸ë¡œ ë§¤í•‘
AZURE_TO_OPENROUTER = {
    "azure_ai:gpt-4.1": "openai/gpt-4.1",
    "gpt41": "openai/gpt-4.1",
    "azure_ai:DeepSeek-V3.1": "deepseek/deepseek-chat-v3.1",
    "deepseek_v31": "deepseek/deepseek-chat-v3.1",
}


def get_openrouter_model(model_id: str, model_name: Optional[str] = None) -> str:
    """
    Azure AI ëª¨ë¸ ID ë˜ëŠ” ëª¨ë¸ ì´ë¦„ì„ OpenRouter ëª¨ë¸ëª…ìœ¼ë¡œ ë³€í™˜

    Args:
        model_id: Azure AI ëª¨ë¸ ID (ì˜ˆ: "azure_ai:gpt-4.1")
        model_name: ëª¨ë¸ ì´ë¦„ (ì˜ˆ: "gpt41", "deepseek_v31")

    Returns:
        OpenRouter ëª¨ë¸ëª… (ì˜ˆ: "openai/gpt-4.1", "deepseek/deepseek-chat-v3.1")
    """
    # 1. model_nameìœ¼ë¡œ ë¨¼ì € í™•ì¸
    if model_name and model_name in AZURE_TO_OPENROUTER:
        return AZURE_TO_OPENROUTER[model_name]

    # 2. model_idë¡œ í™•ì¸
    if model_id in AZURE_TO_OPENROUTER:
        return AZURE_TO_OPENROUTER[model_id]

    # 3. ë§¤í•‘ ì—†ìœ¼ë©´ ì—ëŸ¬
    raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸: model_id={model_id}, model_name={model_name}")


def get_llm(
    model_id: str,
    temperature: float = 0,
    max_tokens: int = 1000,
    use_openrouter: bool = False,
    model_name: Optional[str] = None
):
    """
    LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        model_id: Azure AI ëª¨ë¸ ID (ì˜ˆ: "azure_ai:gpt-4.1")
        temperature: ìƒì„± ì˜¨ë„
        max_tokens: ìµœëŒ€ í† í° ìˆ˜
        use_openrouter: OpenRouterë¥¼ ì‚¬ìš©í• ì§€ ì—¬ë¶€
        model_name: ëª¨ë¸ ì´ë¦„ (ì˜ˆ: "gpt41", "deepseek_v31")

    Returns:
        LangChain ChatModel ì¸ìŠ¤í„´ìŠ¤

    Examples:
        # Azure AI ì‚¬ìš©
        >>> model = get_llm("azure_ai:gpt-4.1", temperature=0.1)

        # OpenRouter ì‚¬ìš© (ìë™ ë§¤í•‘)
        >>> model = get_llm(
        ...     model_id="azure_ai:gpt-4.1",
        ...     model_name="gpt41",
        ...     use_openrouter=True
        ... )
        # -> "openai/gpt-4.1" ëª¨ë¸ ì‚¬ìš©
    """
    # OpenRouter ì‚¬ìš©
    if use_openrouter:
        from app.config.settings import OPENROUTER_API_KEY, OPENROUTER_BASE_URL

        if not OPENROUTER_API_KEY:
            raise ValueError("OPENROUTER_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # OpenRouter ëª¨ë¸ ìë™ ë§¤í•‘
        openrouter_model = get_openrouter_model(model_id, model_name)

        print(f"ğŸ”„ Using OpenRouter: {openrouter_model}")

        return ChatOpenAI(
            base_url=OPENROUTER_BASE_URL,
            api_key=OPENROUTER_API_KEY,
            model=openrouter_model,
            temperature=temperature,
            max_tokens=max_tokens
        )

    # Azure AI ì‚¬ìš© (ê¸°ë³¸ê°’)
    else:
        from app.config.settings import AZURE_AI_CREDENTIAL, AZURE_AI_ENDPOINT

        if not AZURE_AI_CREDENTIAL or not AZURE_AI_ENDPOINT:
            raise ValueError("Azure AI ì„¤ì •ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

        os.environ['AZURE_AI_CREDENTIAL'] = AZURE_AI_CREDENTIAL
        os.environ['AZURE_AI_ENDPOINT'] = AZURE_AI_ENDPOINT

        print(f"ğŸ”„ Using Azure AI: {model_id}")

        return init_chat_model(
            model_id,
            temperature=temperature,
            max_completion_tokens=max_tokens
        )
