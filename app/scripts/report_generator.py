#!/usr/bin/env python3
"""í†µí•© ë³´ê³ ì„œ ìƒì„±ê¸°

ì„¤ì • íŒŒì¼ì„ í†µí•´ ë‹¤ì–‘í•œ íƒ€ì…ì˜ ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- Weekly Report
- Executive Report

ì„¤ì • íŒŒì¼: config/report_config.yaml
"""

import sys
import os
import json
import yaml
import time
import gc
import re
import argparse
import getpass
import traceback
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional

from dotenv import load_dotenv
from langchain.chat_models import init_chat_model

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

from app.config.settings import (
    AZURE_AI_CREDENTIAL,
    AZURE_AI_ENDPOINT,
    QDRANT_DATA_DIR,
    PROMPTS_BASE_DIR
)
from app.utils.langfuse import get_langfuse_client
from app.utils.dates import parse_date_range, extract_date_filter_from_question
from app.utils.common import load_prompt
from app.retrievers.ensemble_retriever import get_ensemble_retriever
from app.retrievers.multiquery_retriever import get_multiquery_retriever
# from app.rerankers import rerank_documents


class ReportGenerator:
    """í†µí•© ë³´ê³ ì„œ ìƒì„±ê¸°

    ì„¤ì • íŒŒì¼ì„ í†µí•´ Retriever, LLM, í”„ë¡¬í”„íŠ¸ë¥¼ ìœ ì—°í•˜ê²Œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """

    def __init__(self, config_path: Optional[str] = None, report_type: Optional[str] = None):
        """
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ. ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ report_config.yaml ì‚¬ìš©.
            report_type: ë³´ê³ ì„œ íƒ€ì… ("weekly", "executive"). ì„¤ì • íŒŒì¼ ë‚´ì—ì„œ í•´ë‹¹ ì„¹ì…˜ ì„ íƒ.
        """
        # ì„¤ì • íŒŒì¼ ë¡œë“œ
        if config_path is None:
            config_path = Path(__file__).parent.parent / "config" / "report_config.yaml"

        with open(config_path, 'r', encoding='utf-8') as f:
            full_config = yaml.safe_load(f)

        # report_typeì— ë”°ë¼ í•´ë‹¹ ì„¹ì…˜ ì„ íƒ
        if report_type is None:
            raise ValueError("report_type ('weekly' ë˜ëŠ” 'executive')ì„ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")

        if report_type == "weekly":
            config = full_config['weekly_report']
        elif report_type == "executive":
            config = full_config['executive_report']
        else:
            raise ValueError(f"Unknown report_type: {report_type}. Use 'weekly' or 'executive'.")

        # ì„¤ì • ì ìš©
        self.report_type = config['report_type']
        self.retriever_config = config['retriever']
        self.llm_config = config['llm']
        self.paths = config['paths']
        self.default_questions = config.get('default_questions', [])

        self.langfuse = get_langfuse_client()

        # ê²½ë¡œë¥¼ í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì„±
        qdrant_lock_subdir = self.paths.get('qdrant_lock_subdir', '')
        self.qdrant_lock = str(Path(QDRANT_DATA_DIR) / qdrant_lock_subdir / '.lock')

        prompts_base_subpath = self.paths.get('prompts_base', '')
        self.prompts_base = str(Path(PROMPTS_BASE_DIR) / prompts_base_subpath)

    def _load_prompt(self, prompt_file: str) -> str:
        """í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ (ë‚´ë¶€ í—¬í¼ ë©”ì„œë“œ)"""
        prompt_path = f"{self.prompts_base}/{prompt_file}"
        return load_prompt(prompt_path)

    def _extract_title_from_answer(self, answer: str) -> str:
        """ë‹µë³€ì—ì„œ ì œëª© ì¶”ì¶œ ([TITLE]...[/TITLE] íƒœê·¸ ì‚¬ìš©)"""
        match = re.search(r'\[TITLE\](.*?)\[/TITLE\]', answer, re.DOTALL)
        if match:
            return match.group(1).strip()
        return None

    def _remove_title_tag_from_answer(self, answer: str) -> str:
        """ë‹µë³€ì—ì„œ ì œëª© íƒœê·¸ ì œê±°"""
        return re.sub(r'\[TITLE\].*?\[/TITLE\]\s*', '', answer, flags=re.DOTALL).strip()

    def _remove_horizontal_lines(self, answer: str) -> str:
        """ë‹µë³€ì—ì„œ ë§ˆí¬ë‹¤ìš´ ìˆ˜í‰ì„ (---) ë° ë¶ˆí•„ìš”í•œ ì¢…ë£Œ íƒœê·¸ ì œê±°"""
        # ìˆ˜í‰ì„  ì œê±°
        answer = re.sub(r'\n---\n', '\n', answer)
        # [END OF REPORT] ë“± ì¢…ë£Œ íƒœê·¸ ì œê±°
        answer = re.sub(r'\n?\[END OF REPORT\]\s*$', '', answer, flags=re.IGNORECASE)
        # (ë), **(ë)** ë“± ì¢…ë£Œ í‘œì‹œ ì œê±°
        answer = re.sub(r'\n?\*?\*?\(ë\)\*?\*?\s*$', '', answer)
        return answer.strip()

    def retrieve_documents(self, question: str, date_filter: Optional[tuple] = None) -> List[Any]:
        """ë¬¸ì„œ ê²€ìƒ‰ - ì„¤ì •ì— ë”°ë¼ RRF Ensemble ë˜ëŠ” RRF MultiQuery ì‚¬ìš©

        Rerankerê°€ í™œì„±í™”ëœ ê²½ìš°, ë” ë§ì€ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•œ í›„ ì¬ìˆœìœ„í™”í•©ë‹ˆë‹¤.
        """
        # Qdrant ë½ íŒŒì¼ ì •ë¦¬
        if os.path.exists(self.qdrant_lock):
            try:
                os.remove(self.qdrant_lock)
            except:
                pass

        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        gc.collect()
        time.sleep(0.5)

        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        os.environ["MODEL_PRESET"] = self.retriever_config['embedding']
        os.environ["USE_EMBEDDING_CACHE"] = "true"

        # Reranker ì„¤ì • í™•ì¸ (ì£¼ì„ì²˜ë¦¬)
        # use_reranker = self.retriever_config.get('use_reranker', False)
        use_reranker = False  # Reranker ë¹„í™œì„±í™”
        final_top_k = self.retriever_config['top_k']

        # Rerankerë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì´ˆê¸° ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ë¥¼ ëŠ˜ë¦¼ (ì£¼ì„ì²˜ë¦¬)
        # if use_reranker:
        #     initial_k = max(20, final_top_k * 3)
        # else:
        #     initial_k = final_top_k
        initial_k = final_top_k  # Reranker ë¹„í™œì„±í™”ë¡œ final_top_k ì‚¬ìš©

        # ê¸°ë³¸ RRF Ensemble ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
        rrf_config = self.retriever_config.get('rrf', {})
        base_retriever = get_ensemble_retriever(
            k=initial_k,
            bm25_weight=rrf_config.get('bm25_weight', 0.5),
            dense_weight=rrf_config.get('dense_weight', 0.5),
            date_filter=date_filter,
            use_mmr=rrf_config.get('use_mmr', True),
            lambda_mult=rrf_config.get('lambda_mult', 0.5)
        )

        # MultiQuery íƒ€ì…ì´ë©´ ë˜í•‘
        if self.retriever_config['type'] == 'rrf_multiquery':
            multiquery_config = self.retriever_config.get('multiquery', {})
            use_openrouter = self.llm_config.get('use_openrouter', False)
            retriever = get_multiquery_retriever(
                base_retriever=base_retriever,
                num_queries=multiquery_config.get('num_queries', 3),
                temperature=multiquery_config.get('temperature', 0.7),
                use_openrouter=use_openrouter
            )
        else:
            retriever = base_retriever

        print(f"ğŸ” ê²€ìƒ‰ ì¤‘... ({self.retriever_config['display_name']})")

        # ë¬¸ì„œ ê²€ìƒ‰
        docs = retriever.invoke(question)

        # ë”ë¯¸ ë¬¸ì„œ í•„í„°ë§ (ë‚ ì§œ í•„í„°ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œê°€ ì—†ì„ ë•Œ ìƒì„±ëœ ë”ë¯¸ ì œê±°)
        docs = [doc for doc in docs if doc.page_content != "no documents found"]

        # ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        if not docs:
            print(f"âš ï¸ ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []

        # Reranker ì‚¬ìš© ë¡œì§ ì£¼ì„ì²˜ë¦¬
        # if use_reranker:
        #     print(f"ğŸ“„ ì´ˆê¸° ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")
        #
        #     # Rerankerë¡œ ì¬ìˆœìœ„í™”
        #     reranker_config = self.retriever_config.get('reranker', {})
        #     batch_size = reranker_config.get('batch_size', None)
        #
        #     docs = rerank_documents(
        #         query=question,
        #         docs=docs,
        #         top_k=final_top_k,
        #         batch_size=batch_size,
        #         initial_k=len(docs)
        #     )
        #
        #     print(f"ğŸ“„ ìµœì¢… ë¬¸ì„œ ìˆ˜: {len(docs)}")
        # else:
        #     print(f"ğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")

        print(f"ğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")  # Reranker ë¹„í™œì„±í™”

        for i, doc in enumerate(docs, 1):
            print(f"  {i}. {doc.metadata.get('page_title', 'Unknown')}")

        return docs

    def generate_answer(self, question: str, docs: List[Any]) -> tuple[str, str]:
        """LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±

        Returns:
            tuple[str, str]: (ë‹µë³€, trace_id)
        """
        from app.utils.llm_factory import get_llm

        # Context êµ¬ì„±
        context_parts = []
        for doc in docs:
            title = doc.metadata.get('page_title', 'Unknown')
            content = doc.page_content
            context_parts.append(f"[{title}]\n{content}\n")

        context_text = "\n".join(context_parts)

        # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        system_prompt = self._load_prompt("system_prompt.txt")
        answer_generation_template = self._load_prompt("answer_generation_prompt.txt")

        # í…œí”Œë¦¿ì— ë³€ìˆ˜ ëŒ€ì…
        user_prompt = answer_generation_template.replace("{context}", context_text).replace("{question}", question)

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        print(f"ğŸ’¬ ë‹µë³€ ìƒì„± ì¤‘... ({self.llm_config['display_name']})")

        # LLM ìƒì„±
        generation_config = self.llm_config.get('generation', {})
        use_openrouter = self.llm_config.get('use_openrouter', False)

        model = get_llm(
            model_id=self.llm_config['model_id'],
            temperature=generation_config.get('temperature', 0),
            max_tokens=generation_config.get('max_completion_tokens', 1000),
            use_openrouter=use_openrouter,
            model_name=self.llm_config['name']
        )

        # Langfuseë¡œ ë‹µë³€ ìƒì„± ê¸°ë¡ (Langfuseê°€ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ)
        trace_id = None
        if self.langfuse:
            with self.langfuse.start_as_current_observation(
                as_type='generation',
                name=f"generation_{self.llm_config['name']}",
                model=self.llm_config['model_id'],
                input={"question": question, "context": context_text[:500] + "..." if len(context_text) > 500 else context_text},
                metadata={"llm": self.llm_config['name'], "num_docs": len(docs), "use_openrouter": use_openrouter}
            ) as generation:
                response = model.invoke(messages)
                answer = response.content

                # trace_id ìº¡ì²˜
                trace_id = generation.trace_id

                # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
                usage_dict = None
                if hasattr(response, 'usage_metadata') and response.usage_metadata:
                    usage_dict = {
                        "input": response.usage_metadata.get('input_tokens', 0),
                        "output": response.usage_metadata.get('output_tokens', 0),
                        "total": response.usage_metadata.get('total_tokens', 0)
                    }

                generation.update(
                    output={"answer": answer},
                    usage=usage_dict if usage_dict else None
                )

                # Trace ì—…ë°ì´íŠ¸
                self.langfuse.update_current_trace(
                    tags=[f"{self.report_type}_report", self.retriever_config['name'], self.llm_config['name']],
                    output={"answer": answer}
                )
        else:
            # Langfuseê°€ ë¹„í™œì„±í™”ëœ ê²½ìš° ì§ì ‘ LLM í˜¸ì¶œ
            response = model.invoke(messages)
            answer = response.content

        print(f"âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ\n")

        return answer, trace_id

    def generate_report(self, questions: List[str], global_date_filter: Optional[tuple] = None) -> Dict[str, Any]:
        """ë³´ê³ ì„œ ìƒì„±

        Args:
            questions: ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
            global_date_filter: ì „ì—­ ë‚ ì§œ í•„í„° (ëª…ì‹œì ìœ¼ë¡œ ì§€ì •ëœ ê²½ìš°, ì§ˆë¬¸ë³„ ì¶”ì¶œë³´ë‹¤ ìš°ì„ )

        Returns:
            ë³´ê³ ì„œ ë°ì´í„°
        """
        report_title = "ì£¼ê°„ ë³´ê³ ì„œ" if self.report_type == "weekly" else "ìµœì¢… ë³´ê³ ì„œ (Executive Report)"

        print("\n" + "=" * 100)
        print(f"ğŸ“Š {report_title} ìƒì„± ì‹œì‘")
        print("=" * 100)
        print(f"ğŸ”§ ì„¤ì •: {self.retriever_config['display_name']} + {self.llm_config['display_name']}")
        if global_date_filter:
            print(f"ğŸ“… ì „ì—­ ë‚ ì§œ í•„í„°: {global_date_filter[0][:10]} ~ {global_date_filter[1][:10]}")
        print(f"ğŸ“ ì§ˆë¬¸ ìˆ˜: {len(questions)}")
        print()

        results = []

        for i, question in enumerate(questions, 1):
            print(f"\n{'=' * 100}")
            print(f"ì§ˆë¬¸ {i}/{len(questions)}")
            print(f"{'=' * 100}")
            print(f"â“ {question}\n")

            try:
                # ë‚ ì§œ í•„í„° ê²°ì •: ì „ì—­ í•„í„°ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒ ì‚¬ìš©, ì—†ìœ¼ë©´ ì§ˆë¬¸ì—ì„œ ì¶”ì¶œ
                if global_date_filter:
                    date_filter = global_date_filter
                else:
                    date_filter = extract_date_filter_from_question(question)
                    if date_filter:
                        print(f"ğŸ“… ê°ì§€ëœ ë‚ ì§œ í•„í„°: {date_filter[0][:10]} ~ {date_filter[1][:10]}\n")

                # ë¬¸ì„œ ê²€ìƒ‰
                docs = self.retrieve_documents(question, date_filter)

                # ë¬¸ì„œê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
                trace_id = None
                if not docs:
                    answer = "í•´ë‹¹ ê¸°ê°„ì— ëŒ€í•œ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    title = "ë¬¸ì„œ ì—†ìŒ"
                else:
                    # ë‹µë³€ ìƒì„± (Langfuse ìë™ ì¶”ì )
                    answer, trace_id = self.generate_answer(question, docs)

                    # ì œëª© ì¶”ì¶œ
                    title = self._extract_title_from_answer(answer)
                    answer = self._remove_title_tag_from_answer(answer)
                    answer = self._remove_horizontal_lines(answer)

                if title:
                    print(f"ğŸ“‹ ì œëª©: {title}")
                print(f"ğŸ“ ë‹µë³€:\n{answer}\n")
                if trace_id:
                    print(f"ğŸ”– Trace ID: {trace_id}\n")

                # ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                images = []
                for doc in docs:
                    if doc.metadata.get('has_image', False):
                        image_paths = doc.metadata.get('image_paths', [])
                        image_descriptions = doc.metadata.get('image_descriptions', [])
                        for img_path, img_desc in zip(image_paths, image_descriptions):
                            images.append({
                                'path': img_path,
                                'description': img_desc,
                                'source': doc.metadata.get('page_title', 'Unknown')
                            })

                if images:
                    print(f"ğŸ–¼ï¸  ì²¨ë¶€ ì´ë¯¸ì§€: {len(images)}ê°œ")
                    for img in images:
                        print(f"  - {img['path']} (ì¶œì²˜: {img['source']})")
                    print()

                results.append({
                    "question_id": i,
                    "question": question,
                    "title": title,  # LLMì´ ìƒì„±í•œ ì œëª© ì¶”ê°€
                    "date_filter": f"{date_filter[0][:10]} ~ {date_filter[1][:10]}" if date_filter else None,
                    "num_docs": len(docs),
                    "doc_titles": [doc.metadata.get('page_title', 'Unknown') for doc in docs],
                    "images": images,  # ì´ë¯¸ì§€ ì •ë³´ ì¶”ê°€
                    "answer": answer,
                    "trace_id": trace_id,  # trace_id ì¶”ê°€
                    "success": True
                })

            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\n")
                traceback.print_exc()

                results.append({
                    "question_id": i,
                    "question": question,
                    "error": str(e),
                    "success": False
                })

        # Langfuse flush (í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ)
        if self.langfuse:
            self.langfuse.flush()

        report_data = {
            "report_type": self.report_type,
            "title": "ì£¼ê°„ ë³´ê³ ì„œ" if self.report_type == "weekly" else "ìµœì¢… ë³´ê³ ì„œ",
            "generated_at": datetime.now().isoformat(),
            "retriever": self.retriever_config,
            "llm": self.llm_config,
            "global_date_filter": f"{global_date_filter[0][:10]} ~ {global_date_filter[1][:10]}" if global_date_filter else None,
            "num_questions": len(questions),
            "results": results
        }

        print("\n" + "=" * 100)
        print(f"âœ… {report_title} ìƒì„± ì™„ë£Œ!")
        print("=" * 100)

        return report_data

    def save_json(self, report_data: Dict[str, Any], output_path: str):
        """JSON íŒŒì¼ë¡œ ì €ì¥"""
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)

        print(f"ğŸ’¾ JSON ì €ì¥: {output_file}")


def main():
    """CLI ì§„ì…ì """
    parser = argparse.ArgumentParser(description="í†µí•© ë³´ê³ ì„œ ìƒì„±ê¸°")
    parser.add_argument("--report-type", type=str, choices=['weekly', 'executive'], required=True,
                       help="ë³´ê³ ì„œ íƒ€ì… (weekly ë˜ëŠ” executive)")
    parser.add_argument("--config", type=str, help="ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ report-typeì— ë”°ë¼ ê¸°ë³¸ê°’ ì‚¬ìš©)")
    parser.add_argument("--questions", type=str, nargs='+', help="ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸")
    parser.add_argument("--date-range", type=str, help="ë‚ ì§œ ë²”ìœ„ (ì˜ˆ: 'ì´ë²ˆ ì£¼', '12ì›” 2ì£¼ì°¨')")
    parser.add_argument("--start-date", type=str, help="ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)")
    parser.add_argument("--end-date", type=str, help="ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)")
    parser.add_argument("--output", type=str, default=None, help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--author", type=str, default=None, help="ë³´ê³ ì„œ ì‘ì„±ì (ë¯¸ì§€ì • ì‹œ ì‹œìŠ¤í…œ ì‚¬ìš©ìëª… ì‚¬ìš©)")

    args = parser.parse_args()

    # ë‚ ì§œ í•„í„° íŒŒì‹±
    date_filter = parse_date_range(
        date_input=args.date_range,
        start_date=args.start_date,
        end_date=args.end_date
    )

    # ë³´ê³ ì„œ ìƒì„±ê¸° ì´ˆê¸°í™”
    generator = ReportGenerator(config_path=args.config, report_type=args.report_type)

    # ì§ˆë¬¸ ì„¤ì •
    if args.questions:
        questions = args.questions
    else:
        # ì„¤ì • íŒŒì¼ì˜ ê¸°ë³¸ ì§ˆë¬¸ ì‚¬ìš©
        questions = generator.default_questions

    # ì‘ì„±ì ì •ë³´ ì„¤ì •
    author = args.author if args.author else getpass.getuser()

    # ë³´ê³ ì„œ ìƒì„±
    report_data = generator.generate_report(questions, date_filter)

    # ì‘ì„±ì ë° ì‘ì„±ì¼ì ì •ë³´ ì¶”ê°€
    report_data["author"] = author
    report_data["created_date"] = datetime.now().strftime("%Y-%m-%d")
    report_data["created_datetime"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # JSON ì €ì¥
    if args.output:
        generator.save_json(report_data, args.output)
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        default_output = f"data/reports/{args.report_type}_report_{timestamp}.json"
        generator.save_json(report_data, default_output)


if __name__ == "__main__":
    main()
