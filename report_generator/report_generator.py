#!/usr/bin/env python3
"""í†µí•© ë³´ê³ ì„œ ìƒì„±ê¸°

ì„¤ì • íŒŒì¼ì„ í†µí•´ ë‹¤ì–‘í•œ íƒ€ì…ì˜ ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- Weekly Report: weekly_report_config.yaml
- Executive Report: executive_report_config.yaml
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from dotenv import load_dotenv
load_dotenv()

import os
import json
import yaml
from datetime import datetime
from typing import List, Dict, Any, Optional
from langchain.chat_models import init_chat_model

from config.settings import AZURE_AI_CREDENTIAL, AZURE_AI_ENDPOINT
from utils.langfuse_utils import get_langfuse_client
from utils.date_utils import parse_date_range, extract_date_filter_from_question
from retrievers.ensemble_retriever import get_ensemble_retriever
from retrievers.multiquery_retriever import get_multiquery_retriever


class ReportGenerator:
    """í†µí•© ë³´ê³ ì„œ ìƒì„±ê¸°

    ì„¤ì • íŒŒì¼ì„ í†µí•´ Retriever, LLM, í”„ë¡¬í”„íŠ¸ë¥¼ ìœ ì—°í•˜ê²Œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """

    def __init__(self, config_path: Optional[str] = None, report_type: Optional[str] = None):
        """
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ. ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ report_typeì— ë”°ë¼ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©.
            report_type: ë³´ê³ ì„œ íƒ€ì… ("weekly", "executive"). config_pathê°€ ì—†ì„ ë•Œë§Œ ì‚¬ìš©.
        """
        # ì„¤ì • íŒŒì¼ ë¡œë“œ
        if config_path is None:
            if report_type == "weekly":
                config_path = Path(__file__).parent.parent / "config" / "weekly_report_config.yaml"
            elif report_type == "executive":
                config_path = Path(__file__).parent.parent / "config" / "executive_report_config.yaml"
            else:
                raise ValueError("config_path ë˜ëŠ” report_type ('weekly' ë˜ëŠ” 'executive') ì¤‘ í•˜ë‚˜ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")

        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)

        # ì„¤ì • ì ìš©
        self.report_type = config['report_type']
        self.retriever_config = config['retriever']
        self.llm_config = config['llm']
        self.paths = config['paths']
        self.default_questions = config.get('default_questions', [])

        self.langfuse = get_langfuse_client()
        self.qdrant_lock = self.paths['qdrant_lock']

    def load_prompt(self, prompt_file: str) -> str:
        """í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ"""
        prompt_path = Path(__file__).parent.parent / self.paths['prompts_base'] / prompt_file
        with open(prompt_path, 'r', encoding='utf-8') as f:
            return f.read()

    def retrieve_documents(self, question: str, date_filter: Optional[tuple] = None) -> List[Any]:
        """ë¬¸ì„œ ê²€ìƒ‰ - ì„¤ì •ì— ë”°ë¼ RRF Ensemble ë˜ëŠ” RRF MultiQuery ì‚¬ìš©"""
        import time
        import gc

        # Qdrant ë½ íŒŒì¼ ì •ë¦¬
        if os.path.exists(self.qdrant_lock):
            try:
                os.remove(self.qdrant_lock)
            except:
                pass

        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        gc.collect()
        time.sleep(0.5)

        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        os.environ["MODEL_PRESET"] = self.retriever_config['embedding']
        os.environ["USE_EMBEDDING_CACHE"] = "true"

        # ê¸°ë³¸ RRF Ensemble ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
        rrf_config = self.retriever_config.get('rrf', {})
        base_retriever = get_ensemble_retriever(
            k=self.retriever_config['top_k'],
            bm25_weight=rrf_config.get('bm25_weight', 0.5),
            dense_weight=rrf_config.get('dense_weight', 0.5),
            date_filter=date_filter
        )

        # MultiQuery íƒ€ì…ì´ë©´ ë˜í•‘
        if self.retriever_config['type'] == 'rrf_multiquery':
            multiquery_config = self.retriever_config.get('multiquery', {})
            retriever = get_multiquery_retriever(
                base_retriever=base_retriever,
                num_queries=multiquery_config.get('num_queries', 3),
                temperature=multiquery_config.get('temperature', 0.7)
            )
        else:
            retriever = base_retriever

        print(f"ğŸ” ê²€ìƒ‰ ì¤‘... ({self.retriever_config['display_name']})")

        # ë¬¸ì„œ ê²€ìƒ‰
        docs = retriever.invoke(question)

        print(f"ğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")
        for i, doc in enumerate(docs, 1):
            print(f"  {i}. {doc.metadata.get('page_title', 'Unknown')}")

        return docs

    def generate_answer(self, question: str, docs: List[Any]) -> str:
        """LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±"""
        # Context êµ¬ì„±
        context_parts = []
        for i, doc in enumerate(docs, 1):
            title = doc.metadata.get('page_title', 'Unknown')
            content = doc.page_content
            context_parts.append(f"[ë¬¸ì„œ {i}] {title}\n{content}\n")

        context_text = "\n".join(context_parts)

        # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        system_prompt = self.load_prompt("system_prompt.txt")
        answer_generation_template = self.load_prompt("answer_generation_prompt.txt")

        # í…œí”Œë¦¿ì— ë³€ìˆ˜ ëŒ€ì…
        user_prompt = answer_generation_template.replace("{context}", context_text).replace("{question}", question)

        # Azure AI ì„¤ì •
        os.environ['AZURE_AI_CREDENTIAL'] = AZURE_AI_CREDENTIAL
        os.environ['AZURE_AI_ENDPOINT'] = AZURE_AI_ENDPOINT

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        print(f"ğŸ’¬ ë‹µë³€ ìƒì„± ì¤‘... ({self.llm_config['display_name']})")

        # LLM ìƒì„±
        generation_config = self.llm_config.get('generation', {})
        model = init_chat_model(
            self.llm_config['model_id'],
            temperature=generation_config.get('temperature', 0),
            max_completion_tokens=generation_config.get('max_completion_tokens', 1000)
        )

        # Langfuseë¡œ ë‹µë³€ ìƒì„± ê¸°ë¡
        with self.langfuse.start_as_current_observation(
            as_type='generation',
            name=f"generation_{self.llm_config['name']}",
            model=self.llm_config['model_id'],
            input={"question": question, "context": context_text[:500] + "..." if len(context_text) > 500 else context_text},
            metadata={"llm": self.llm_config['name'], "num_docs": len(docs)}
        ) as generation:
            response = model.invoke(messages)
            answer = response.content

            # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
            usage_dict = None
            if hasattr(response, 'usage_metadata') and response.usage_metadata:
                usage_dict = {
                    "input": response.usage_metadata.get('input_tokens', 0),
                    "output": response.usage_metadata.get('output_tokens', 0),
                    "total": response.usage_metadata.get('total_tokens', 0)
                }

            generation.update(
                output={"answer": answer},
                usage=usage_dict if usage_dict else None
            )

            # Trace ì—…ë°ì´íŠ¸
            self.langfuse.update_current_trace(
                tags=[f"{self.report_type}_report", self.retriever_config['name'], self.llm_config['name']],
                output={"answer": answer}
            )

        print(f"âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ\n")

        return answer

    def generate_report(self, questions: List[str], global_date_filter: Optional[tuple] = None) -> Dict[str, Any]:
        """ë³´ê³ ì„œ ìƒì„±

        Args:
            questions: ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
            global_date_filter: ì „ì—­ ë‚ ì§œ í•„í„° (ëª…ì‹œì ìœ¼ë¡œ ì§€ì •ëœ ê²½ìš°, ì§ˆë¬¸ë³„ ì¶”ì¶œë³´ë‹¤ ìš°ì„ )

        Returns:
            ë³´ê³ ì„œ ë°ì´í„°
        """
        report_title = "ì£¼ê°„ ë³´ê³ ì„œ" if self.report_type == "weekly" else "ìµœì¢… ë³´ê³ ì„œ (Executive Report)"

        print("\n" + "=" * 100)
        print(f"ğŸ“Š {report_title} ìƒì„± ì‹œì‘")
        print("=" * 100)
        print(f"ğŸ”§ ì„¤ì •: {self.retriever_config['display_name']} + {self.llm_config['display_name']}")
        if global_date_filter:
            print(f"ğŸ“… ì „ì—­ ë‚ ì§œ í•„í„°: {global_date_filter[0][:10]} ~ {global_date_filter[1][:10]}")
        print(f"ğŸ“ ì§ˆë¬¸ ìˆ˜: {len(questions)}")
        print()

        results = []

        for i, question in enumerate(questions, 1):
            print(f"\n{'=' * 100}")
            print(f"ì§ˆë¬¸ {i}/{len(questions)}")
            print(f"{'=' * 100}")
            print(f"â“ {question}\n")

            try:
                # ë‚ ì§œ í•„í„° ê²°ì •: ì „ì—­ í•„í„°ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒ ì‚¬ìš©, ì—†ìœ¼ë©´ ì§ˆë¬¸ì—ì„œ ì¶”ì¶œ
                if global_date_filter:
                    date_filter = global_date_filter
                else:
                    date_filter = extract_date_filter_from_question(question)
                    if date_filter:
                        print(f"ğŸ“… ê°ì§€ëœ ë‚ ì§œ í•„í„°: {date_filter[0][:10]} ~ {date_filter[1][:10]}\n")

                # ë¬¸ì„œ ê²€ìƒ‰
                docs = self.retrieve_documents(question, date_filter)

                # ë‹µë³€ ìƒì„± (Langfuse ìë™ ì¶”ì )
                answer = self.generate_answer(question, docs)

                print(f"ğŸ“ ë‹µë³€:\n{answer}\n")

                results.append({
                    "question_id": i,
                    "question": question,
                    "date_filter": f"{date_filter[0][:10]} ~ {date_filter[1][:10]}" if date_filter else None,
                    "num_docs": len(docs),
                    "doc_titles": [doc.metadata.get('page_title', 'Unknown') for doc in docs],
                    "answer": answer,
                    "success": True
                })

            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\n")
                import traceback
                traceback.print_exc()

                results.append({
                    "question_id": i,
                    "question": question,
                    "error": str(e),
                    "success": False
                })

        # Langfuse flush
        self.langfuse.flush()

        report_data = {
            "report_type": self.report_type,
            "generated_at": datetime.now().isoformat(),
            "retriever": self.retriever_config,
            "llm": self.llm_config,
            "global_date_filter": f"{global_date_filter[0][:10]} ~ {global_date_filter[1][:10]}" if global_date_filter else None,
            "num_questions": len(questions),
            "results": results
        }

        print("\n" + "=" * 100)
        print(f"âœ… {report_title} ìƒì„± ì™„ë£Œ!")
        print("=" * 100)

        return report_data

    def save_json(self, report_data: Dict[str, Any], output_path: str):
        """JSON íŒŒì¼ë¡œ ì €ì¥"""
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)

        print(f"ğŸ’¾ JSON ì €ì¥: {output_file}")


def main():
    import argparse

    parser = argparse.ArgumentParser(description="í†µí•© ë³´ê³ ì„œ ìƒì„±ê¸°")
    parser.add_argument("--report-type", type=str, choices=['weekly', 'executive'], required=True,
                       help="ë³´ê³ ì„œ íƒ€ì… (weekly ë˜ëŠ” executive)")
    parser.add_argument("--config", type=str, help="ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ report-typeì— ë”°ë¼ ê¸°ë³¸ê°’ ì‚¬ìš©)")
    parser.add_argument("--questions", type=str, nargs='+', help="ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸")
    parser.add_argument("--date-range", type=str, help="ë‚ ì§œ ë²”ìœ„ (ì˜ˆ: 'ì´ë²ˆ ì£¼', '12ì›” 2ì£¼ì°¨')")
    parser.add_argument("--start-date", type=str, help="ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)")
    parser.add_argument("--end-date", type=str, help="ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)")
    parser.add_argument("--output", type=str, default=None, help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ")

    args = parser.parse_args()

    # ë‚ ì§œ í•„í„° íŒŒì‹±
    date_filter = parse_date_range(
        date_input=args.date_range,
        start_date=args.start_date,
        end_date=args.end_date
    )

    # ë³´ê³ ì„œ ìƒì„±ê¸° ì´ˆê¸°í™”
    generator = ReportGenerator(config_path=args.config, report_type=args.report_type)

    # ì§ˆë¬¸ ì„¤ì •
    if args.questions:
        questions = args.questions
    else:
        # ì„¤ì • íŒŒì¼ì˜ ê¸°ë³¸ ì§ˆë¬¸ ì‚¬ìš©
        questions = generator.default_questions

    # ë³´ê³ ì„œ ìƒì„±
    report_data = generator.generate_report(questions, date_filter)

    # JSON ì €ì¥
    if args.output:
        generator.save_json(report_data, args.output)
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        default_output = f"data/reports/{args.report_type}_report_{timestamp}.json"
        generator.save_json(report_data, default_output)


if __name__ == "__main__":
    main()
